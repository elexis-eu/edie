"""
    ELEXIS Protocol for accessing dictionaries

    This protocol allows data to be shared with the ELEXIS platform and should be implemented by all providers of data to the ELEXIS platform. This is an OpenAPI documentation, for more details about using this specification, please refer to OpenAPI documentations: https://swagger.io/resources/articles/documenting-apis-with-swagger/  # noqa: E501

    The version of the OpenAPI document: 1.0
    Generated by: https://openapi-generator.tech
"""

import unittest
import json

from edie.model import JsonEntry, Metadata, JsonApiResponse
from metrics.base import NumberOfSensesEvaluator, PublisherEvaluator, LicenseEvaluator, MetadataQuantityEvaluator, \
    RecencyEvaluator, ApiMetadataResponseEvaluator, DefinitionOfSenseEvaluator, AvgDefinitionLengthEvaluator


class TestEntry(unittest.TestCase):
    """Entry unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def testEntry(self):
        """Test Entry"""
        # FIXME: construct object with mandatory attributes with example values
        # model = Entry()  # noqa: E501
        pass


class TestDefinitionOfSenses(unittest.TestCase):
    def setUp(self) -> None:
        pass

    def tearDown(self) -> None:
        pass

    def test_definition_of_sense_init(self) -> None:
        evaluator = DefinitionOfSenseEvaluator()

        self.assertEqual(evaluator.senses_count, 0)
        self.assertEqual(evaluator.definition_count, 0)
        self.assertEqual(evaluator.entry_count, 0)

    def test_reset(self) -> None:
        evaluator = DefinitionOfSenseEvaluator()
        with open("test/data/entries.json") as f:
            entry_json = json.load(f)

            entry: JsonEntry = JsonEntry(entry_json)
            evaluator.accumulate(entry)

        evaluator.reset()

        self.assertEqual(evaluator.senses_count, 0)
        self.assertEqual(evaluator.definition_count, 0)
        self.assertEqual(evaluator.entry_count, 0)

    def test_result(self) -> None:
        evaluator = DefinitionOfSenseEvaluator()
        with open("test/data/entries.json") as f:
            entry_json = json.load(f)
            entry: JsonEntry = JsonEntry(entry_json)
            evaluator.accumulate(entry)

        result = evaluator.result()

        self.assertEqual(result['DefinitionPerSense'], 1.0)
        self.assertEqual(result['DefinitionPerEntry'], 1.0)

    def test_entry(self) -> None:
        with open("test/data/entries.json") as f:
            entry_json = json.load(f)
            entry: JsonEntry = JsonEntry(entry_json)
            evaluator = DefinitionOfSenseEvaluator()

            evaluator.accumulate(entry)

        self.assertEqual(evaluator.entry_count, 1)
        self.assertEqual(evaluator.senses_count, 1)
        self.assertEqual(evaluator.definition_count, 1)


class TestNumberOfSenses(unittest.TestCase):

    def setUp(self):
        self.numberOfSensesEvaluator: NumberOfSensesEvaluator = NumberOfSensesEvaluator()

    def tearDown(self):
        pass

    def testEntry(self):
        f = open("test/data/entries.json")
        entry_json = json.load(f)
        f.close()

        entry: JsonEntry = JsonEntry(entry_json)  # TODO: should be Entry()

        evaluator = NumberOfSensesEvaluator()

        evaluator.accumulate(entry)

        self.assertEqual(evaluator.senses_count, 1)
        self.assertEqual(evaluator.entry_count, 1)


class TestPublisherMetadata(unittest.TestCase):

    def setUp(self) -> None:
        pass

    def tearDown(self) -> None:
        pass

    def test_publisher_metadata_init(self) -> None:
        evaluator = PublisherEvaluator()
        self.assertEqual(evaluator.publisher, '')
        self.assertFalse(evaluator.publisher_info_present)

    def test_reset(self) -> None:
        evaluator = PublisherEvaluator()
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()
        metadata_entry: Metadata = Metadata(entry_json)
        evaluator.analyze(metadata_entry)

        evaluator.reset()

        self.assertEqual(evaluator.publisher, '')
        self.assertFalse(evaluator.publisher_info_present)

    def test_result(self) -> None:
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()

        metadata_entry: Metadata = Metadata(entry_json)

        evaluator = PublisherEvaluator()
        evaluator.analyze(metadata_entry)
        result = evaluator.result()
        self.assertIsNotNone(result['publisher'])

    def test_entry(self) -> None:
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()

        metadata_entry: Metadata = Metadata(entry_json)

        evaluator = PublisherEvaluator()
        evaluator.analyze(metadata_entry)
        self.assertTrue(evaluator.publisher_info_present, 'Publisher info missing')


class TestLicence(unittest.TestCase):
    def setUp(self) -> None:
        pass

    def tearDown(self) -> None:
        pass

    def test_license_init(self) -> None:
        evaluator = LicenseEvaluator()
        self.assertEqual(evaluator.license, '')
        self.assertFalse(evaluator.license_info_present)

    def test_reset(self) -> None:
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()

        metadata_entry: Metadata = Metadata(entry_json)
        evaluator = LicenseEvaluator()
        evaluator.analyze(metadata_entry)

        evaluator.reset()
        self.assertEqual(evaluator.license, '')
        self.assertFalse(evaluator.license_info_present)

    def test_result(self) -> None:
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()

        metadata_entry: Metadata = Metadata(entry_json)

        evaluator = LicenseEvaluator()
        evaluator.analyze(metadata_entry)
        result = evaluator.result()

        self.assertIsNotNone(result['license'])

    def test_entry(self) -> None:
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()

        metadata_entry: Metadata = Metadata(entry_json)

        evaluator = LicenseEvaluator()
        evaluator.analyze(metadata_entry)
        self.assertTrue(evaluator.license_info_present, 'License info missing')


class TestRecency(unittest.TestCase):

    def setUp(self) -> None:
        pass

    def tearDown(self) -> None:
        pass

    def test_recency_init(self) -> None:
        evaluator = RecencyEvaluator()
        self.assertEqual(evaluator.recency, None)

    def test_reset(self) -> None:
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()

        metadata_entry: Metadata = Metadata(entry_json)
        evaluator = RecencyEvaluator()
        evaluator.analyze(metadata_entry)

        evaluator.reset()
        self.assertEqual(evaluator.recency, None)

    def test_result(self) -> None:
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()

        metadata_entry: Metadata = Metadata(entry_json)

        evaluator = RecencyEvaluator()
        evaluator.analyze(metadata_entry)
        result = evaluator.result()
        self.assertIsNotNone(result['recency'])

    def test_entry(self) -> None:
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()

        metadata_entry: Metadata = Metadata(entry_json)

        evaluator = RecencyEvaluator()
        evaluator.analyze(metadata_entry)
        self.assertIsNotNone(evaluator.recency, 'Cannot estimate recency')
        self.assertLessEqual(evaluator.recency, 50, 'Dictionary is older than 50 years')


class TestMetadataQuantity(unittest.TestCase):

    def setUp(self) -> None:
        pass

    def tearDown(self) -> None:
        pass

    def test_metadata_quantity_init(self) -> None:
        evaluator = MetadataQuantityEvaluator()
        self.assertEqual(evaluator.metric_count, 0)
        self.assertEqual(evaluator.total_metrics, 0)

    def test_reset(self) -> None:
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()

        metadata_entry: Metadata = Metadata(entry_json)

        evaluator = MetadataQuantityEvaluator()
        evaluator.analyze(metadata_entry)
        evaluator.reset()

        self.assertEqual(evaluator.metric_count, 0)
        self.assertEqual(evaluator.total_metrics, 0)

    def test_result(self) -> None:
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()

        metadata_entry: Metadata = Metadata(entry_json)

        evaluator = MetadataQuantityEvaluator()
        evaluator.analyze(metadata_entry)
        # print(str(evaluator.metric_count) +'/'+str(evaluator.total_metrics))
        # TODO - what is the expected ratio?
        result = evaluator.result()
        self.assertIsNotNone(result['metric count'])
        self.assertIsNotNone(result['total metrics'])

    def test_entry(self) -> None:
        f = open("test/data/sample.json")
        entry_json = json.load(f)
        f.close()

        metadata_entry: Metadata = Metadata(entry_json)

        evaluator = MetadataQuantityEvaluator()
        evaluator.analyze(metadata_entry)
        self.assertGreaterEqual(evaluator.metric_count, evaluator.total_metrics / 10, 'Less than 10% of metadata')


class TestMetadataApiResponse(unittest.TestCase):

    def setUp(self) -> None:
        pass

    def tearDown(self) -> None:
        pass

    def test_metadata_api_response_init(self) -> None:
        evaluator = ApiMetadataResponseEvaluator()
        self.assertEqual(len(evaluator.languages), 0)
        self.assertEqual(evaluator.dict_count, 0)

    def test_reset(self) -> None:
        f = open("test/data/lexonomy.json")
        entry_json = json.load(f)
        f.close()

        api_entry: JsonApiResponse = JsonApiResponse(entry_json)
        evaluator = ApiMetadataResponseEvaluator()

        evaluator.analyze(api_entry)

        evaluator.reset()

        self.assertEqual(len(evaluator.languages), 0)
        self.assertEqual(evaluator.dict_count, 0)

    def test_result(self) -> None:
        f = open("test/data/lexonomy.json")
        entry_json = json.load(f)
        f.close()

        api_entry: JsonApiResponse = JsonApiResponse(entry_json)
        evaluator = ApiMetadataResponseEvaluator()

        evaluator.analyze(api_entry)
        result = evaluator.result()

        self.assertIsNotNone(result['dictionary count'])

    def test_entry(self) -> None:
        f = open("test/data/lexonomy.json")
        entry_json = json.load(f)
        f.close()

        api_entry: JsonApiResponse = JsonApiResponse(entry_json)
        evaluator = ApiMetadataResponseEvaluator()

        evaluator.analyze(api_entry)

        self.assertGreaterEqual(evaluator.dict_count, 1)


if __name__ == '__main__':
    unittest.main()
